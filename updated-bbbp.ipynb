{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5661186,"sourceType":"datasetVersion","datasetId":3253806}],"dockerImageVersionId":30474,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## AI - Project - S2DV - Group 28 and Group 50\n\n> Sachin Kumar Gupta  21075074\n\n> Kushagra Gupta      21075049\n\n> Harmanjot Singh     21075037\n\n> Ruchira Naskar      21075072","metadata":{}},{"cell_type":"markdown","source":"**Blood brain barrier penetration**\n\n\nProblem Statement : Prediction of Binary labels of blood-brain barrier penetration(permeability) using Keras Neural Network Model and also using XGBoost for Boosting.","metadata":{}},{"cell_type":"markdown","source":"The blood-brain barrier (BBB) is a highly selective barrier that separates the circulating blood from the brain extracellular fluid. It plays a crucial role in maintaining the stability of the brain's internal environment and protecting it from potentially harmful substances. However, there are certain circumstances where penetration of the BBB is desired, particularly for drug delivery to treat various neurological disorders.\n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-13T04:17:30.532060Z","iopub.execute_input":"2023-05-13T04:17:30.532416Z","iopub.status.idle":"2023-05-13T04:17:30.560076Z","shell.execute_reply.started":"2023-05-13T04:17:30.532389Z","shell.execute_reply":"2023-05-13T04:17:30.558863Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"**Importing necessary packages**","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import KernelPCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.calibration import CalibratedClassifierCV\nimport pickle\nfrom keras.layers import Dense, Activation, Dropout, BatchNormalization, Input\nfrom keras.models import Sequential, Model\nfrom keras import optimizers, regularizers, initializers\nfrom keras.callbacks import ModelCheckpoint, Callback\nfrom keras import backend as K\nfrom keras.optimizers import Adam\nimport tensorflow as tf\nfrom xgboost import XGBClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"96413d12d4ca227ace5c9c07766f4f317f89511b","execution":{"iopub.status.busy":"2023-05-13T04:17:30.561820Z","iopub.execute_input":"2023-05-13T04:17:30.562166Z","iopub.status.idle":"2023-05-13T04:17:37.969407Z","shell.execute_reply.started":"2023-05-13T04:17:30.562133Z","shell.execute_reply":"2023-05-13T04:17:37.968332Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"**Initalising the constants**","metadata":{}},{"cell_type":"code","source":"NCA1 = 100\nNCA2 = 50\nDROPRATE = 0.2\nEP = 500\nBATCH_SIZE = 256\nVAL_RATIO = 0.1\nTEST_RATIO = 0.1","metadata":{"_uuid":"a317a8478e0802bd232504777e5b5f970e3a788a","execution":{"iopub.status.busy":"2023-05-13T04:17:37.970532Z","iopub.execute_input":"2023-05-13T04:17:37.971003Z","iopub.status.idle":"2023-05-13T04:17:37.976006Z","shell.execute_reply.started":"2023-05-13T04:17:37.970982Z","shell.execute_reply":"2023-05-13T04:17:37.974837Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"NCA1 = 100: It represents the number of neurons (or units) in the first hidden layer of a neural network model. The value of 100 indicates that there are 100 neurons in this particular layer.\n\nNCA2 = 50: This constant represents the number of neurons in the second hidden layer of the neural network model. In this case, there are 50 neurons in this layer.\n\nDROPRATE = 0.2: This constant represents the dropout rate in the neural network model. Dropout is a regularization technique used to prevent overfitting by randomly dropping out (setting to zero) a fraction of the neurons during training. A dropout rate of 0.2 indicates that 20% of the neurons in the model will be dropped out during training.\n\nEP = 500: EP likely stands for epochs, which refers to the number of times the neural network model will iterate over the entire training dataset during training. In this case, the model will go through 500 epochs.\n\nBATCH_SIZE = 256: Batch size refers to the number of training examples utilized in each iteration of the model during the training process. A batch size of 256 means that the model will process 256 training examples at a time before updating the model's parameters.\n\nVAL_RATIO = 0.1: This constant represents the validation ratio, which indicates the proportion of the training data that will be set aside for validation during training. A validation ratio of 0.1 means that 10% of the training data will be used for validation.\n\nTEST_RATIO = 0.1: Similarly, the test ratio represents the proportion of the entire dataset that will be reserved for testing the trained model's performance. A test ratio of 0.1 indicates that 10% of the data will be used for testing.","metadata":{}},{"cell_type":"markdown","source":"**Loading the BBBP Dataset**\n\nBBBP: Binary labels of blood-brain barrier penetration(permeability).","metadata":{"_uuid":"0917ba0d9889194b44548e8e1d8f935f83b8c9eb"}},{"cell_type":"code","source":"bbbp_df= pd.read_csv('/kaggle/input/bbbp-dataset-ai-project/BBBP (1).csv')\nprint(bbbp_df.shape)\nbbbp_df.head()","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2023-05-13T04:17:37.978640Z","iopub.execute_input":"2023-05-13T04:17:37.978996Z","iopub.status.idle":"2023-05-13T04:17:38.035659Z","shell.execute_reply.started":"2023-05-13T04:17:37.978964Z","shell.execute_reply":"2023-05-13T04:17:38.034799Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(2039, 4)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   num                  name  label  \\\n0    1            Propanolol      1   \n1    2  Terbutylchlorambucil      1   \n2    3                 40730      1   \n3    4                    24      1   \n4    5           cloxacillin      1   \n\n                                              smiles  \n0                   [Cl].CC(C)NCC(O)COc1cccc2ccccc12  \n1           C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl  \n2  c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO...  \n3                   C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C  \n4  Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num</th>\n      <th>name</th>\n      <th>label</th>\n      <th>smiles</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Propanolol</td>\n      <td>1</td>\n      <td>[Cl].CC(C)NCC(O)COc1cccc2ccccc12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Terbutylchlorambucil</td>\n      <td>1</td>\n      <td>C(=O)(OC(C)(C)C)CCCc1ccc(cc1)N(CCCl)CCCl</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>40730</td>\n      <td>1</td>\n      <td>c12c3c(N4CCN(C)CC4)c(F)cc1c(c(C(O)=O)cn2C(C)CO...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>24</td>\n      <td>1</td>\n      <td>C1CCN(CC1)Cc1cccc(c1)OCCCNC(=O)C</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>cloxacillin</td>\n      <td>1</td>\n      <td>Cc1onc(c2ccccc2Cl)c1C(=O)N[C@H]3[C@H]4SC(C)(C)...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"The simplified molecular-input line-entry system (**SMILES**) is a specification in form of a line notation for describing the structure of chemical species using short ASCII strings. SMILES can be converted to molecular structure by using RDKIT module.\n\nExample: \n```python\nfrom rdkit import Chem\nm = Chem.MolFromSmiles('Cc1ccccc1')\n```\n","metadata":{"_uuid":"352c491782c8b62ce6904b5f3c85d0222805f34d"}},{"cell_type":"code","source":"bbbp_df['label'].value_counts()","metadata":{"_uuid":"9fdb5b794648cc805159594527b6aec7abe5b494","execution":{"iopub.status.busy":"2023-05-13T04:17:38.036863Z","iopub.execute_input":"2023-05-13T04:17:38.037206Z","iopub.status.idle":"2023-05-13T04:17:38.049841Z","shell.execute_reply.started":"2023-05-13T04:17:38.037177Z","shell.execute_reply":"2023-05-13T04:17:38.048790Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"1    1560\n0     479\nName: label, dtype: int64"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"In the dataset used we have counted the number of label values that have the value 1 whose value is **1560** and the number of label values having the value 0 is **469**","metadata":{}},{"cell_type":"markdown","source":"## Feature Extration","metadata":{}},{"cell_type":"markdown","source":"* Installing the rdkit library that will be used for feature extraction","metadata":{}},{"cell_type":"code","source":"# !conda install -c rdkit rdkit -y","metadata":{"execution":{"iopub.status.busy":"2023-05-13T04:17:38.051057Z","iopub.execute_input":"2023-05-13T04:17:38.051438Z","iopub.status.idle":"2023-05-13T04:17:38.056097Z","shell.execute_reply.started":"2023-05-13T04:17:38.051401Z","shell.execute_reply":"2023-05-13T04:17:38.055184Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"* Here feature will be extracted for all the SMILES and will be stored in a output file.","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# from rdkit import Chem\n# from rdkit.Chem import Descriptors\n\n# # Read the SMILES and label from the input CSV file\n# input_file = '/kaggle/input/bbbp-dataset-ai-project/BBBP (1).csv'\n# output_file = 'features.csv'\n# data = pd.read_csv(input_file)\n\n# # Create a new DataFrame to store the extracted features\n# output_data = pd.DataFrame()\n\n# # Iterate over the SMILES and extract the features\n# for index, row in data.iterrows():\n#     smiles = row['smiles']\n#     label = row['label']\n#     molecule = Chem.MolFromSmiles(smiles)\n    \n#     # Calculate the features using RDKit descriptors\n#     features = {'smiles': smiles, 'label': label}\n    \n#     for descriptor_name, descriptor_func in Descriptors.descList:\n#         descriptor_value = descriptor_func(molecule)\n#         features[descriptor_name] = descriptor_value\n    \n#     # Append the features to the output DataFrame\n#     output_data = output_data.append(features, ignore_index=True)\n\n# # Save the extracted features to a new CSV file\n# output_data.to_csv(output_file, index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T04:17:38.057077Z","iopub.execute_input":"2023-05-13T04:17:38.057661Z","iopub.status.idle":"2023-05-13T04:17:38.066717Z","shell.execute_reply.started":"2023-05-13T04:17:38.057626Z","shell.execute_reply":"2023-05-13T04:17:38.065306Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## To calculate the descripter using mordred that we are using in the model","metadata":{}},{"cell_type":"code","source":"# !pip install mordred rdkit\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T04:17:38.068425Z","iopub.execute_input":"2023-05-13T04:17:38.068757Z","iopub.status.idle":"2023-05-13T04:17:38.079115Z","shell.execute_reply.started":"2023-05-13T04:17:38.068731Z","shell.execute_reply":"2023-05-13T04:17:38.078427Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"**We are using the desciptor mentioned here in order to create descriptor file https://mordred-descriptor.github.io/documentation/master/descriptors.html**\n\n1826 column will be added in the new file after extraction","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# from rdkit import Chem\n# from mordred import Calculator, descriptors\n\n# # Load the input CSV file\n# input_file = \"/content/BBBP (1).csv\"\n# data = pd.read_csv(input_file)\n\n# # Extract the SMILES column\n# smiles = data['smiles']\n\n# # Initialize the calculator with desired descriptors\n# calc = Calculator(descriptors, ignore_3D=True)  # You can add more descriptors if needed\n\n# # Calculate descriptors for each SMILES molecule\n# desc_list = []\n# invalid_smiles = []\n# for sm in smiles:\n#     mol = Chem.MolFromSmiles(sm)\n#     if mol is None:\n#         invalid_smiles.append(sm)\n#     else:\n#         desc = calc(mol)\n#         desc_list.append(desc)\n\n# # Combine descriptors with original data\n# output_data = pd.concat([data, pd.DataFrame(desc_list)], axis=1)\n\n# # Save the output to a new CSV file\n# output_file = \"BBBP_descriptors_df.csv\"\n# output_data.to_csv(output_file, index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T04:17:38.080182Z","iopub.execute_input":"2023-05-13T04:17:38.080770Z","iopub.status.idle":"2023-05-13T04:17:38.088806Z","shell.execute_reply.started":"2023-05-13T04:17:38.080736Z","shell.execute_reply":"2023-05-13T04:17:38.088077Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Loading molecular descriptors or Features that were already obtained.\n\n**Descriptors dataframe contains 1625 molecular descriptors (including 3D descriptors) generated on the NCI database using Mordred python module.**\n","metadata":{"_uuid":"33af3e6f48775ebb81d3e34fd19a82955b58a64a"}},{"cell_type":"markdown","source":"**Now we are using the obtained feature or descripters to implement the data in the model.**","metadata":{}},{"cell_type":"code","source":"bbbp_descriptors_df= pd.read_csv('/kaggle/input/bbbp-dataset-ai-project/BBBP_descriptors_df.csv',low_memory=False)\nprint(bbbp_descriptors_df.shape)\nbbbp_descriptors_df.head()","metadata":{"_uuid":"988b649adfb69cfc43f0d8d7f084608b6e845842","execution":{"iopub.status.busy":"2023-05-13T04:17:38.091540Z","iopub.execute_input":"2023-05-13T04:17:38.092542Z","iopub.status.idle":"2023-05-13T04:17:40.249251Z","shell.execute_reply.started":"2023-05-13T04:17:38.092512Z","shell.execute_reply":"2023-05-13T04:17:40.248119Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(2039, 1825)\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"         ABC      ABCGG  nAcid  nBase                             SpAbs_A  \\\n0  14.389425  11.808563      0      1  multiple fragments (SpAbs_A/SpAbs)   \n1  16.809162  13.974216      0      0                   27.07079790976892   \n2  20.758034  16.164169      1      1                  33.465822016594636   \n3  15.775129  12.193243      0      1                  26.569834753519054   \n4  23.095142  19.875288      1      0                   36.20647450941663   \n\n                              SpMax_A                              SpDiam_A  \\\n0  multiple fragments (SpMax_A/SpMax)  multiple fragments (SpDiam_A/SpDiam)   \n1                  2.2954078760731984                     4.590815752146396   \n2                  2.5785233443199886                     5.157046688639976   \n3                  2.2810418592150574                     4.562083718430117   \n4                  2.6329498486229084                     5.121946098165539   \n\n                             SpAD_A                             SpMAD_A  \\\n0  multiple fragments (SpAD_A/SpAD)  multiple fragments (SpMAD_A/SpMAD)   \n1                 27.07079790976892                   1.176991213468214   \n2                33.465822016594636                  1.2871470006382553   \n3                26.569834753519054                  1.2652302263580502   \n4                 36.20647450941663                  1.2484991210143666   \n\n                              LogEE_A  ...      SRW10     TSRW10          MW  \\\n0  multiple fragments (LogEE_A/LogEE)  ...   9.604475  52.719904  294.126082   \n1                   4.006826078023401  ...   9.620262  56.206491  359.141884   \n2                   4.212470854925482  ...  10.513498  61.857420  361.143784   \n3                  3.9370258695924103  ...   9.441849  53.624898  290.199428   \n4                   4.326727233654511  ...  10.721173  82.182989  435.065569   \n\n        AMW       WPath WPol  Zagreb1  Zagreb2  \\\n0  7.173807  1900000792   25     92.0    103.0   \n1  7.182838        1492   28    106.0    114.0   \n2  7.850952        1484   51    146.0    180.0   \n3  6.174456        1158   24     98.0    106.0   \n4  9.256714        2212   50    164.0    203.0   \n\n                                         mZagreb1  mZagreb2  \n0  divide by zero encountered in power (mZagreb1)  4.305556  \n1                               9.506944444444443  5.319444  \n2                               9.333333333333334  5.527778  \n3                               6.194444444444445  4.833333  \n4                              11.395833333333332  6.097222  \n\n[5 rows x 1825 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ABC</th>\n      <th>ABCGG</th>\n      <th>nAcid</th>\n      <th>nBase</th>\n      <th>SpAbs_A</th>\n      <th>SpMax_A</th>\n      <th>SpDiam_A</th>\n      <th>SpAD_A</th>\n      <th>SpMAD_A</th>\n      <th>LogEE_A</th>\n      <th>...</th>\n      <th>SRW10</th>\n      <th>TSRW10</th>\n      <th>MW</th>\n      <th>AMW</th>\n      <th>WPath</th>\n      <th>WPol</th>\n      <th>Zagreb1</th>\n      <th>Zagreb2</th>\n      <th>mZagreb1</th>\n      <th>mZagreb2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14.389425</td>\n      <td>11.808563</td>\n      <td>0</td>\n      <td>1</td>\n      <td>multiple fragments (SpAbs_A/SpAbs)</td>\n      <td>multiple fragments (SpMax_A/SpMax)</td>\n      <td>multiple fragments (SpDiam_A/SpDiam)</td>\n      <td>multiple fragments (SpAD_A/SpAD)</td>\n      <td>multiple fragments (SpMAD_A/SpMAD)</td>\n      <td>multiple fragments (LogEE_A/LogEE)</td>\n      <td>...</td>\n      <td>9.604475</td>\n      <td>52.719904</td>\n      <td>294.126082</td>\n      <td>7.173807</td>\n      <td>1900000792</td>\n      <td>25</td>\n      <td>92.0</td>\n      <td>103.0</td>\n      <td>divide by zero encountered in power (mZagreb1)</td>\n      <td>4.305556</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16.809162</td>\n      <td>13.974216</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27.07079790976892</td>\n      <td>2.2954078760731984</td>\n      <td>4.590815752146396</td>\n      <td>27.07079790976892</td>\n      <td>1.176991213468214</td>\n      <td>4.006826078023401</td>\n      <td>...</td>\n      <td>9.620262</td>\n      <td>56.206491</td>\n      <td>359.141884</td>\n      <td>7.182838</td>\n      <td>1492</td>\n      <td>28</td>\n      <td>106.0</td>\n      <td>114.0</td>\n      <td>9.506944444444443</td>\n      <td>5.319444</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20.758034</td>\n      <td>16.164169</td>\n      <td>1</td>\n      <td>1</td>\n      <td>33.465822016594636</td>\n      <td>2.5785233443199886</td>\n      <td>5.157046688639976</td>\n      <td>33.465822016594636</td>\n      <td>1.2871470006382553</td>\n      <td>4.212470854925482</td>\n      <td>...</td>\n      <td>10.513498</td>\n      <td>61.857420</td>\n      <td>361.143784</td>\n      <td>7.850952</td>\n      <td>1484</td>\n      <td>51</td>\n      <td>146.0</td>\n      <td>180.0</td>\n      <td>9.333333333333334</td>\n      <td>5.527778</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15.775129</td>\n      <td>12.193243</td>\n      <td>0</td>\n      <td>1</td>\n      <td>26.569834753519054</td>\n      <td>2.2810418592150574</td>\n      <td>4.562083718430117</td>\n      <td>26.569834753519054</td>\n      <td>1.2652302263580502</td>\n      <td>3.9370258695924103</td>\n      <td>...</td>\n      <td>9.441849</td>\n      <td>53.624898</td>\n      <td>290.199428</td>\n      <td>6.174456</td>\n      <td>1158</td>\n      <td>24</td>\n      <td>98.0</td>\n      <td>106.0</td>\n      <td>6.194444444444445</td>\n      <td>4.833333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23.095142</td>\n      <td>19.875288</td>\n      <td>1</td>\n      <td>0</td>\n      <td>36.20647450941663</td>\n      <td>2.6329498486229084</td>\n      <td>5.121946098165539</td>\n      <td>36.20647450941663</td>\n      <td>1.2484991210143666</td>\n      <td>4.326727233654511</td>\n      <td>...</td>\n      <td>10.721173</td>\n      <td>82.182989</td>\n      <td>435.065569</td>\n      <td>9.256714</td>\n      <td>2212</td>\n      <td>50</td>\n      <td>164.0</td>\n      <td>203.0</td>\n      <td>11.395833333333332</td>\n      <td>6.097222</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1825 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"Shape of the **Features' Data**","metadata":{}},{"cell_type":"code","source":"data_features = bbbp_descriptors_df;\nprint(data_features.shape);","metadata":{"execution":{"iopub.status.busy":"2023-05-13T04:17:40.251216Z","iopub.execute_input":"2023-05-13T04:17:40.252149Z","iopub.status.idle":"2023-05-13T04:17:40.257287Z","shell.execute_reply.started":"2023-05-13T04:17:40.252119Z","shell.execute_reply":"2023-05-13T04:17:40.256245Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(2039, 1825)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# function to coerce all data types to numeric\n\ndef coerce_to_numeric(df, column_list):\n    df[column_list] = df[column_list].apply(pd.to_numeric, errors='coerce')","metadata":{"scrolled":true,"_uuid":"9ddb2cfb56587b305160a9f8f4d15413915f7773","execution":{"iopub.status.busy":"2023-05-13T04:17:40.258947Z","iopub.execute_input":"2023-05-13T04:17:40.259271Z","iopub.status.idle":"2023-05-13T04:17:40.267982Z","shell.execute_reply.started":"2023-05-13T04:17:40.259241Z","shell.execute_reply":"2023-05-13T04:17:40.266684Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"coerce_to_numeric(bbbp_descriptors_df, bbbp_descriptors_df.columns)\nbbbp_descriptors_df.head()","metadata":{"_uuid":"33e25f00d71457264a433a8301ec1d44b1aa235e","execution":{"iopub.status.busy":"2023-05-13T04:17:40.269530Z","iopub.execute_input":"2023-05-13T04:17:40.269964Z","iopub.status.idle":"2023-05-13T04:17:50.007120Z","shell.execute_reply.started":"2023-05-13T04:17:40.269930Z","shell.execute_reply":"2023-05-13T04:17:50.006041Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"         ABC      ABCGG  nAcid  nBase    SpAbs_A   SpMax_A  SpDiam_A  \\\n0  14.389425  11.808563      0      1        NaN       NaN       NaN   \n1  16.809162  13.974216      0      0  27.070798  2.295408  4.590816   \n2  20.758034  16.164169      1      1  33.465822  2.578523  5.157047   \n3  15.775129  12.193243      0      1  26.569835  2.281042  4.562084   \n4  23.095142  19.875288      1      0  36.206475  2.632950  5.121946   \n\n      SpAD_A   SpMAD_A   LogEE_A  ...      SRW10     TSRW10          MW  \\\n0        NaN       NaN       NaN  ...   9.604475  52.719904  294.126082   \n1  27.070798  1.176991  4.006826  ...   9.620262  56.206491  359.141884   \n2  33.465822  1.287147  4.212471  ...  10.513498  61.857420  361.143784   \n3  26.569835  1.265230  3.937026  ...   9.441849  53.624898  290.199428   \n4  36.206475  1.248499  4.326727  ...  10.721173  82.182989  435.065569   \n\n        AMW       WPath  WPol  Zagreb1  Zagreb2   mZagreb1  mZagreb2  \n0  7.173807  1900000792    25     92.0    103.0        NaN  4.305556  \n1  7.182838        1492    28    106.0    114.0   9.506944  5.319444  \n2  7.850952        1484    51    146.0    180.0   9.333333  5.527778  \n3  6.174456        1158    24     98.0    106.0   6.194444  4.833333  \n4  9.256714        2212    50    164.0    203.0  11.395833  6.097222  \n\n[5 rows x 1825 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ABC</th>\n      <th>ABCGG</th>\n      <th>nAcid</th>\n      <th>nBase</th>\n      <th>SpAbs_A</th>\n      <th>SpMax_A</th>\n      <th>SpDiam_A</th>\n      <th>SpAD_A</th>\n      <th>SpMAD_A</th>\n      <th>LogEE_A</th>\n      <th>...</th>\n      <th>SRW10</th>\n      <th>TSRW10</th>\n      <th>MW</th>\n      <th>AMW</th>\n      <th>WPath</th>\n      <th>WPol</th>\n      <th>Zagreb1</th>\n      <th>Zagreb2</th>\n      <th>mZagreb1</th>\n      <th>mZagreb2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14.389425</td>\n      <td>11.808563</td>\n      <td>0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>9.604475</td>\n      <td>52.719904</td>\n      <td>294.126082</td>\n      <td>7.173807</td>\n      <td>1900000792</td>\n      <td>25</td>\n      <td>92.0</td>\n      <td>103.0</td>\n      <td>NaN</td>\n      <td>4.305556</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16.809162</td>\n      <td>13.974216</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27.070798</td>\n      <td>2.295408</td>\n      <td>4.590816</td>\n      <td>27.070798</td>\n      <td>1.176991</td>\n      <td>4.006826</td>\n      <td>...</td>\n      <td>9.620262</td>\n      <td>56.206491</td>\n      <td>359.141884</td>\n      <td>7.182838</td>\n      <td>1492</td>\n      <td>28</td>\n      <td>106.0</td>\n      <td>114.0</td>\n      <td>9.506944</td>\n      <td>5.319444</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20.758034</td>\n      <td>16.164169</td>\n      <td>1</td>\n      <td>1</td>\n      <td>33.465822</td>\n      <td>2.578523</td>\n      <td>5.157047</td>\n      <td>33.465822</td>\n      <td>1.287147</td>\n      <td>4.212471</td>\n      <td>...</td>\n      <td>10.513498</td>\n      <td>61.857420</td>\n      <td>361.143784</td>\n      <td>7.850952</td>\n      <td>1484</td>\n      <td>51</td>\n      <td>146.0</td>\n      <td>180.0</td>\n      <td>9.333333</td>\n      <td>5.527778</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15.775129</td>\n      <td>12.193243</td>\n      <td>0</td>\n      <td>1</td>\n      <td>26.569835</td>\n      <td>2.281042</td>\n      <td>4.562084</td>\n      <td>26.569835</td>\n      <td>1.265230</td>\n      <td>3.937026</td>\n      <td>...</td>\n      <td>9.441849</td>\n      <td>53.624898</td>\n      <td>290.199428</td>\n      <td>6.174456</td>\n      <td>1158</td>\n      <td>24</td>\n      <td>98.0</td>\n      <td>106.0</td>\n      <td>6.194444</td>\n      <td>4.833333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23.095142</td>\n      <td>19.875288</td>\n      <td>1</td>\n      <td>0</td>\n      <td>36.206475</td>\n      <td>2.632950</td>\n      <td>5.121946</td>\n      <td>36.206475</td>\n      <td>1.248499</td>\n      <td>4.326727</td>\n      <td>...</td>\n      <td>10.721173</td>\n      <td>82.182989</td>\n      <td>435.065569</td>\n      <td>9.256714</td>\n      <td>2212</td>\n      <td>50</td>\n      <td>164.0</td>\n      <td>203.0</td>\n      <td>11.395833</td>\n      <td>6.097222</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1825 columns</p>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"**If the NAN values are present in the table we are changing it to 0**","metadata":{}},{"cell_type":"code","source":"bbbp_descriptors_df = bbbp_descriptors_df.fillna(0)\nbbbp_descriptors_df.head()","metadata":{"_uuid":"6d300a694864c8caaf83547b50f112ec7b49ed98","execution":{"iopub.status.busy":"2023-05-13T04:17:50.008445Z","iopub.execute_input":"2023-05-13T04:17:50.008778Z","iopub.status.idle":"2023-05-13T04:17:50.061741Z","shell.execute_reply.started":"2023-05-13T04:17:50.008748Z","shell.execute_reply":"2023-05-13T04:17:50.060897Z"},"trusted":true},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"         ABC      ABCGG  nAcid  nBase    SpAbs_A   SpMax_A  SpDiam_A  \\\n0  14.389425  11.808563      0      1   0.000000  0.000000  0.000000   \n1  16.809162  13.974216      0      0  27.070798  2.295408  4.590816   \n2  20.758034  16.164169      1      1  33.465822  2.578523  5.157047   \n3  15.775129  12.193243      0      1  26.569835  2.281042  4.562084   \n4  23.095142  19.875288      1      0  36.206475  2.632950  5.121946   \n\n      SpAD_A   SpMAD_A   LogEE_A  ...      SRW10     TSRW10          MW  \\\n0   0.000000  0.000000  0.000000  ...   9.604475  52.719904  294.126082   \n1  27.070798  1.176991  4.006826  ...   9.620262  56.206491  359.141884   \n2  33.465822  1.287147  4.212471  ...  10.513498  61.857420  361.143784   \n3  26.569835  1.265230  3.937026  ...   9.441849  53.624898  290.199428   \n4  36.206475  1.248499  4.326727  ...  10.721173  82.182989  435.065569   \n\n        AMW       WPath  WPol  Zagreb1  Zagreb2   mZagreb1  mZagreb2  \n0  7.173807  1900000792    25     92.0    103.0   0.000000  4.305556  \n1  7.182838        1492    28    106.0    114.0   9.506944  5.319444  \n2  7.850952        1484    51    146.0    180.0   9.333333  5.527778  \n3  6.174456        1158    24     98.0    106.0   6.194444  4.833333  \n4  9.256714        2212    50    164.0    203.0  11.395833  6.097222  \n\n[5 rows x 1825 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ABC</th>\n      <th>ABCGG</th>\n      <th>nAcid</th>\n      <th>nBase</th>\n      <th>SpAbs_A</th>\n      <th>SpMax_A</th>\n      <th>SpDiam_A</th>\n      <th>SpAD_A</th>\n      <th>SpMAD_A</th>\n      <th>LogEE_A</th>\n      <th>...</th>\n      <th>SRW10</th>\n      <th>TSRW10</th>\n      <th>MW</th>\n      <th>AMW</th>\n      <th>WPath</th>\n      <th>WPol</th>\n      <th>Zagreb1</th>\n      <th>Zagreb2</th>\n      <th>mZagreb1</th>\n      <th>mZagreb2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14.389425</td>\n      <td>11.808563</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>9.604475</td>\n      <td>52.719904</td>\n      <td>294.126082</td>\n      <td>7.173807</td>\n      <td>1900000792</td>\n      <td>25</td>\n      <td>92.0</td>\n      <td>103.0</td>\n      <td>0.000000</td>\n      <td>4.305556</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16.809162</td>\n      <td>13.974216</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27.070798</td>\n      <td>2.295408</td>\n      <td>4.590816</td>\n      <td>27.070798</td>\n      <td>1.176991</td>\n      <td>4.006826</td>\n      <td>...</td>\n      <td>9.620262</td>\n      <td>56.206491</td>\n      <td>359.141884</td>\n      <td>7.182838</td>\n      <td>1492</td>\n      <td>28</td>\n      <td>106.0</td>\n      <td>114.0</td>\n      <td>9.506944</td>\n      <td>5.319444</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20.758034</td>\n      <td>16.164169</td>\n      <td>1</td>\n      <td>1</td>\n      <td>33.465822</td>\n      <td>2.578523</td>\n      <td>5.157047</td>\n      <td>33.465822</td>\n      <td>1.287147</td>\n      <td>4.212471</td>\n      <td>...</td>\n      <td>10.513498</td>\n      <td>61.857420</td>\n      <td>361.143784</td>\n      <td>7.850952</td>\n      <td>1484</td>\n      <td>51</td>\n      <td>146.0</td>\n      <td>180.0</td>\n      <td>9.333333</td>\n      <td>5.527778</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15.775129</td>\n      <td>12.193243</td>\n      <td>0</td>\n      <td>1</td>\n      <td>26.569835</td>\n      <td>2.281042</td>\n      <td>4.562084</td>\n      <td>26.569835</td>\n      <td>1.265230</td>\n      <td>3.937026</td>\n      <td>...</td>\n      <td>9.441849</td>\n      <td>53.624898</td>\n      <td>290.199428</td>\n      <td>6.174456</td>\n      <td>1158</td>\n      <td>24</td>\n      <td>98.0</td>\n      <td>106.0</td>\n      <td>6.194444</td>\n      <td>4.833333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23.095142</td>\n      <td>19.875288</td>\n      <td>1</td>\n      <td>0</td>\n      <td>36.206475</td>\n      <td>2.632950</td>\n      <td>5.121946</td>\n      <td>36.206475</td>\n      <td>1.248499</td>\n      <td>4.326727</td>\n      <td>...</td>\n      <td>10.721173</td>\n      <td>82.182989</td>\n      <td>435.065569</td>\n      <td>9.256714</td>\n      <td>2212</td>\n      <td>50</td>\n      <td>164.0</td>\n      <td>203.0</td>\n      <td>11.395833</td>\n      <td>6.097222</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1825 columns</p>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## KNN\n\nThe k-nearest neighbors algorithm, also known as KNN or k-NN, is a non-parametric, supervised learning classifier, which uses proximity to make classifications or predictions about the grouping of an individual data point.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Step 1: Load the CSV files\nsmiles_df = pd.read_csv('/kaggle/input/bbbp-dataset-ai-project/BBBP (1).csv')\ndescriptor_df = pd.read_csv('/kaggle/input/bbbp-dataset-ai-project/BBBP_descriptors_df.csv')\n\n# Step 2: Combine the data\ncombined_df = pd.concat([smiles_df, descriptor_df], axis=1)\n\n# Step 3: Preprocess the data\nfeatures = combined_df.drop(['label'], axis=1)\n\n# Remove non-numeric or string columns\nnumeric_cols = features.select_dtypes(include=['float64', 'int64']).columns\nfeatures = features[numeric_cols]\n\nlabels = combined_df['label']\n\n# Step 4: Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n\n# Step 5: Normalize the features\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Step 6: Train the KNN model\nk = 5  # Number of neighbors to consider\nknn = KNeighborsClassifier(n_neighbors=k)\nknn.fit(X_train_scaled, y_train)\n\n# Step 7: Predict the labels\ny_pred = knn.predict(X_test_scaled)\n\n# Step 8: Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\nclassification_report = classification_report(y_test, y_pred)\nprint(f'Classification Report:\\n{classification_report}')\n\n# Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T04:17:50.062772Z","iopub.execute_input":"2023-05-13T04:17:50.063042Z","iopub.status.idle":"2023-05-13T04:17:51.746664Z","shell.execute_reply.started":"2023-05-13T04:17:50.063020Z","shell.execute_reply":"2023-05-13T04:17:51.744940Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Accuracy: 0.8553921568627451\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.78      0.57      0.65        99\n           1       0.87      0.95      0.91       309\n\n    accuracy                           0.86       408\n   macro avg       0.82      0.76      0.78       408\nweighted avg       0.85      0.86      0.85       408\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"# Using XGBoost","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Step 1: Load the CSV files\nsmiles_df = pd.read_csv('/kaggle/input/bbbp-dataset-ai-project/BBBP (1).csv')\ndescriptor_df = pd.read_csv('/kaggle/input/bbbp-dataset-ai-project/BBBP_descriptors_df.csv')\n\n# Step 2: Combine the data\ncombined_df = pd.concat([smiles_df, descriptor_df], axis=1)\n\n# Step 3: Preprocess the data\nfeatures = combined_df.drop(['label'], axis=1)\n\n# Remove non-numeric or string columns\nnumeric_cols = features.select_dtypes(include=['float64', 'int64']).columns\nfeatures = features[numeric_cols]\n\nlabels = combined_df['label']\n\n# Step 4: Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n\n# Step 5: Normalize the features\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Step 6: Train the XGBoost model\nxgb = XGBClassifier()\nxgb.fit(X_train_scaled, y_train)\n\n# Step 7: Predict the labels\ny_pred = xgb.predict(X_test_scaled)\n\n# Step 8: Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\n\nclassification_report = classification_report(y_test, y_pred)\nprint(f'Classification Report:\\n{classification_report}')\n\n# Plot Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, cmap='Blues', fmt='g', cbar=False)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T04:17:51.748137Z","iopub.execute_input":"2023-05-13T04:17:51.748455Z","iopub.status.idle":"2023-05-13T04:17:57.303279Z","shell.execute_reply.started":"2023-05-13T04:17:51.748427Z","shell.execute_reply":"2023-05-13T04:17:57.302609Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Accuracy: 0.9093137254901961\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.85      0.76      0.80        99\n           1       0.93      0.96      0.94       309\n\n    accuracy                           0.91       408\n   macro avg       0.89      0.86      0.87       408\nweighted avg       0.91      0.91      0.91       408\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"## DNN Model to predict the label","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n# Step 1: Load the CSV files\nsmiles_df = pd.read_csv('/kaggle/input/bbbp-dataset-ai-project/BBBP (1).csv')\ndescriptor_df = pd.read_csv('/kaggle/input/bbbp-dataset-ai-project/BBBP_descriptors_df.csv')\n\n# Step 2: Combine the data\ncombined_df = pd.concat([smiles_df, descriptor_df], axis=1)\n\n# Step 3: Preprocess the data\nfeatures = combined_df.drop(['label'], axis=1)\n\n# Remove non-numeric or string columns\nnumeric_cols = features.select_dtypes(include=['float64', 'int64']).columns\nfeatures = features[numeric_cols]\n\nlabels = combined_df['label']\n\n# Step 4: Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n\n# Step 5: Normalize the features\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Step 6: Build the DNN model\nmodel = Sequential()\nmodel.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Step 7: Compile and train the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhistory = model.fit(X_train_scaled, y_train, epochs=200, batch_size=32, validation_data=(X_test_scaled, y_test))\n\n# Step 8: Evaluate the model\nloss, accuracy = model.evaluate(X_test_scaled, y_test)\nprint(f'Accuracy: {accuracy}')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T04:17:57.304395Z","iopub.execute_input":"2023-05-13T04:17:57.304792Z","iopub.status.idle":"2023-05-13T04:18:32.628209Z","shell.execute_reply.started":"2023-05-13T04:17:57.304765Z","shell.execute_reply":"2023-05-13T04:18:32.627448Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/200\n51/51 [==============================] - 1s 6ms/step - loss: 0.5062 - accuracy: 0.7836 - val_loss: 0.4687 - val_accuracy: 0.7868\nEpoch 2/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.8498 - val_loss: 0.4040 - val_accuracy: 0.8309\nEpoch 3/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.8731 - val_loss: 0.3764 - val_accuracy: 0.8480\nEpoch 4/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.8694 - val_loss: 0.4030 - val_accuracy: 0.8333\nEpoch 5/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.8780 - val_loss: 0.3591 - val_accuracy: 0.8333\nEpoch 6/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2969 - accuracy: 0.8823 - val_loss: 0.3409 - val_accuracy: 0.8431\nEpoch 7/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2893 - accuracy: 0.8835 - val_loss: 0.3365 - val_accuracy: 0.8676\nEpoch 8/200\n51/51 [==============================] - 0s 4ms/step - loss: 0.2737 - accuracy: 0.8884 - val_loss: 0.3500 - val_accuracy: 0.8358\nEpoch 9/200\n51/51 [==============================] - 0s 4ms/step - loss: 0.2687 - accuracy: 0.8866 - val_loss: 0.3421 - val_accuracy: 0.8652\nEpoch 10/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2542 - accuracy: 0.8964 - val_loss: 0.3419 - val_accuracy: 0.8382\nEpoch 11/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2415 - accuracy: 0.8976 - val_loss: 0.3249 - val_accuracy: 0.8456\nEpoch 12/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2400 - accuracy: 0.9037 - val_loss: 0.3248 - val_accuracy: 0.8456\nEpoch 13/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.9013 - val_loss: 0.3180 - val_accuracy: 0.8431\nEpoch 14/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2627 - accuracy: 0.8945 - val_loss: 0.2949 - val_accuracy: 0.8848\nEpoch 15/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2384 - accuracy: 0.8994 - val_loss: 0.3190 - val_accuracy: 0.8725\nEpoch 16/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2234 - accuracy: 0.9044 - val_loss: 0.2978 - val_accuracy: 0.8824\nEpoch 17/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2209 - accuracy: 0.9129 - val_loss: 0.2891 - val_accuracy: 0.8799\nEpoch 18/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2234 - accuracy: 0.9135 - val_loss: 0.2939 - val_accuracy: 0.8701\nEpoch 19/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 0.9129 - val_loss: 0.3004 - val_accuracy: 0.8848\nEpoch 20/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2066 - accuracy: 0.9154 - val_loss: 0.2972 - val_accuracy: 0.8824\nEpoch 21/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2113 - accuracy: 0.9178 - val_loss: 0.2910 - val_accuracy: 0.8824\nEpoch 22/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1978 - accuracy: 0.9215 - val_loss: 0.2881 - val_accuracy: 0.8824\nEpoch 23/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9129 - val_loss: 0.2932 - val_accuracy: 0.8775\nEpoch 24/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2044 - accuracy: 0.9215 - val_loss: 0.2923 - val_accuracy: 0.8922\nEpoch 25/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9080 - val_loss: 0.3139 - val_accuracy: 0.8775\nEpoch 26/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1958 - accuracy: 0.9215 - val_loss: 0.2867 - val_accuracy: 0.8824\nEpoch 27/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1981 - accuracy: 0.9172 - val_loss: 0.2893 - val_accuracy: 0.8848\nEpoch 28/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9074 - val_loss: 0.2879 - val_accuracy: 0.8824\nEpoch 29/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1927 - accuracy: 0.9240 - val_loss: 0.3239 - val_accuracy: 0.8725\nEpoch 30/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9252 - val_loss: 0.2907 - val_accuracy: 0.8897\nEpoch 31/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1963 - accuracy: 0.9221 - val_loss: 0.3008 - val_accuracy: 0.8873\nEpoch 32/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.2134 - accuracy: 0.9105 - val_loss: 0.3172 - val_accuracy: 0.8750\nEpoch 33/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1843 - accuracy: 0.9264 - val_loss: 0.2862 - val_accuracy: 0.8897\nEpoch 34/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1818 - accuracy: 0.9227 - val_loss: 0.3276 - val_accuracy: 0.8750\nEpoch 35/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1987 - accuracy: 0.9234 - val_loss: 0.2934 - val_accuracy: 0.8946\nEpoch 36/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1848 - accuracy: 0.9295 - val_loss: 0.2853 - val_accuracy: 0.8922\nEpoch 37/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.9295 - val_loss: 0.3136 - val_accuracy: 0.8799\nEpoch 38/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1805 - accuracy: 0.9289 - val_loss: 0.3131 - val_accuracy: 0.8799\nEpoch 39/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1765 - accuracy: 0.9295 - val_loss: 0.2973 - val_accuracy: 0.8922\nEpoch 40/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1709 - accuracy: 0.9326 - val_loss: 0.2986 - val_accuracy: 0.8799\nEpoch 41/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9258 - val_loss: 0.2932 - val_accuracy: 0.8971\nEpoch 42/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1698 - accuracy: 0.9350 - val_loss: 0.3065 - val_accuracy: 0.8922\nEpoch 43/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9289 - val_loss: 0.3089 - val_accuracy: 0.8775\nEpoch 44/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1672 - accuracy: 0.9368 - val_loss: 0.3111 - val_accuracy: 0.8848\nEpoch 45/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1662 - accuracy: 0.9332 - val_loss: 0.3001 - val_accuracy: 0.8971\nEpoch 46/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1675 - accuracy: 0.9338 - val_loss: 0.3095 - val_accuracy: 0.8946\nEpoch 47/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9356 - val_loss: 0.3010 - val_accuracy: 0.9044\nEpoch 48/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1539 - accuracy: 0.9368 - val_loss: 0.3175 - val_accuracy: 0.8799\nEpoch 49/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1594 - accuracy: 0.9326 - val_loss: 0.3250 - val_accuracy: 0.8799\nEpoch 50/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9381 - val_loss: 0.3424 - val_accuracy: 0.8775\nEpoch 51/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 0.9454 - val_loss: 0.3248 - val_accuracy: 0.8824\nEpoch 52/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1422 - accuracy: 0.9485 - val_loss: 0.3077 - val_accuracy: 0.8897\nEpoch 53/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1382 - accuracy: 0.9460 - val_loss: 0.3089 - val_accuracy: 0.8873\nEpoch 54/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9418 - val_loss: 0.3458 - val_accuracy: 0.8799\nEpoch 55/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9350 - val_loss: 0.3667 - val_accuracy: 0.8725\nEpoch 56/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9411 - val_loss: 0.3135 - val_accuracy: 0.8824\nEpoch 57/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1410 - accuracy: 0.9436 - val_loss: 0.3301 - val_accuracy: 0.8922\nEpoch 58/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9418 - val_loss: 0.3211 - val_accuracy: 0.8922\nEpoch 59/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1311 - accuracy: 0.9516 - val_loss: 0.3258 - val_accuracy: 0.8897\nEpoch 60/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9460 - val_loss: 0.3145 - val_accuracy: 0.8946\nEpoch 61/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1344 - accuracy: 0.9467 - val_loss: 0.3404 - val_accuracy: 0.8799\nEpoch 62/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9467 - val_loss: 0.3310 - val_accuracy: 0.8922\nEpoch 63/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1212 - accuracy: 0.9503 - val_loss: 0.3939 - val_accuracy: 0.8824\nEpoch 64/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 0.9448 - val_loss: 0.3833 - val_accuracy: 0.8627\nEpoch 65/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9393 - val_loss: 0.3220 - val_accuracy: 0.8922\nEpoch 66/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1401 - accuracy: 0.9448 - val_loss: 0.3203 - val_accuracy: 0.8922\nEpoch 67/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1207 - accuracy: 0.9522 - val_loss: 0.3345 - val_accuracy: 0.8824\nEpoch 68/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1185 - accuracy: 0.9522 - val_loss: 0.3193 - val_accuracy: 0.8995\nEpoch 69/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1108 - accuracy: 0.9577 - val_loss: 0.3403 - val_accuracy: 0.8897\nEpoch 70/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9565 - val_loss: 0.3276 - val_accuracy: 0.8824\nEpoch 71/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1282 - accuracy: 0.9485 - val_loss: 0.3602 - val_accuracy: 0.8873\nEpoch 72/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1083 - accuracy: 0.9571 - val_loss: 0.3314 - val_accuracy: 0.8848\nEpoch 73/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 0.9503 - val_loss: 0.3298 - val_accuracy: 0.8922\nEpoch 74/200\n51/51 [==============================] - 0s 4ms/step - loss: 0.0995 - accuracy: 0.9583 - val_loss: 0.3403 - val_accuracy: 0.8873\nEpoch 75/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1014 - accuracy: 0.9638 - val_loss: 0.4020 - val_accuracy: 0.8848\nEpoch 76/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1172 - accuracy: 0.9510 - val_loss: 0.3640 - val_accuracy: 0.8922\nEpoch 77/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9583 - val_loss: 0.3441 - val_accuracy: 0.8946\nEpoch 78/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1049 - accuracy: 0.9595 - val_loss: 0.3629 - val_accuracy: 0.9044\nEpoch 79/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9614 - val_loss: 0.3383 - val_accuracy: 0.8799\nEpoch 80/200\n51/51 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9595 - val_loss: 0.3725 - val_accuracy: 0.8799\nEpoch 81/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0932 - accuracy: 0.9663 - val_loss: 0.3779 - val_accuracy: 0.8848\nEpoch 82/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9620 - val_loss: 0.3740 - val_accuracy: 0.8995\nEpoch 83/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9614 - val_loss: 0.3513 - val_accuracy: 0.8897\nEpoch 84/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0886 - accuracy: 0.9669 - val_loss: 0.4118 - val_accuracy: 0.8971\nEpoch 85/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9614 - val_loss: 0.3586 - val_accuracy: 0.8897\nEpoch 86/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.9516 - val_loss: 0.4011 - val_accuracy: 0.8897\nEpoch 87/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9706 - val_loss: 0.3940 - val_accuracy: 0.8922\nEpoch 88/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0947 - accuracy: 0.9614 - val_loss: 0.3771 - val_accuracy: 0.8922\nEpoch 89/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9724 - val_loss: 0.4009 - val_accuracy: 0.8897\nEpoch 90/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0934 - accuracy: 0.9651 - val_loss: 0.4550 - val_accuracy: 0.8897\nEpoch 91/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0840 - accuracy: 0.9632 - val_loss: 0.4259 - val_accuracy: 0.8799\nEpoch 92/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9687 - val_loss: 0.3945 - val_accuracy: 0.8922\nEpoch 93/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9638 - val_loss: 0.4295 - val_accuracy: 0.8922\nEpoch 94/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0853 - accuracy: 0.9651 - val_loss: 0.4250 - val_accuracy: 0.8897\nEpoch 95/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9749 - val_loss: 0.4054 - val_accuracy: 0.8922\nEpoch 96/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 0.9742 - val_loss: 0.4312 - val_accuracy: 0.8848\nEpoch 97/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0621 - accuracy: 0.9792 - val_loss: 0.4432 - val_accuracy: 0.8922\nEpoch 98/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9742 - val_loss: 0.4371 - val_accuracy: 0.8676\nEpoch 99/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9681 - val_loss: 0.5499 - val_accuracy: 0.8824\nEpoch 100/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9718 - val_loss: 0.4262 - val_accuracy: 0.8873\nEpoch 101/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9767 - val_loss: 0.4325 - val_accuracy: 0.8946\nEpoch 102/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9798 - val_loss: 0.5048 - val_accuracy: 0.8848\nEpoch 103/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9651 - val_loss: 0.4594 - val_accuracy: 0.8897\nEpoch 104/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0748 - accuracy: 0.9681 - val_loss: 0.4696 - val_accuracy: 0.8946\nEpoch 105/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9767 - val_loss: 0.4175 - val_accuracy: 0.8873\nEpoch 106/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9798 - val_loss: 0.4641 - val_accuracy: 0.8873\nEpoch 107/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.4282 - val_accuracy: 0.8824\nEpoch 108/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9773 - val_loss: 0.5101 - val_accuracy: 0.8897\nEpoch 109/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9785 - val_loss: 0.4680 - val_accuracy: 0.8897\nEpoch 110/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9859 - val_loss: 0.4792 - val_accuracy: 0.8848\nEpoch 111/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9822 - val_loss: 0.4492 - val_accuracy: 0.8922\nEpoch 112/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9779 - val_loss: 0.4986 - val_accuracy: 0.8946\nEpoch 113/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9822 - val_loss: 0.4906 - val_accuracy: 0.8897\nEpoch 114/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9865 - val_loss: 0.4976 - val_accuracy: 0.8946\nEpoch 115/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9834 - val_loss: 0.5421 - val_accuracy: 0.8848\nEpoch 116/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9749 - val_loss: 0.4773 - val_accuracy: 0.8995\nEpoch 117/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0499 - accuracy: 0.9853 - val_loss: 0.5100 - val_accuracy: 0.8775\nEpoch 118/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9822 - val_loss: 0.5413 - val_accuracy: 0.8922\nEpoch 119/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9828 - val_loss: 0.5095 - val_accuracy: 0.8897\nEpoch 120/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9859 - val_loss: 0.4633 - val_accuracy: 0.8971\nEpoch 121/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9804 - val_loss: 0.5024 - val_accuracy: 0.8897\nEpoch 122/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9828 - val_loss: 0.6067 - val_accuracy: 0.8824\nEpoch 123/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9871 - val_loss: 0.4991 - val_accuracy: 0.8946\nEpoch 124/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0494 - accuracy: 0.9810 - val_loss: 0.5058 - val_accuracy: 0.8897\nEpoch 125/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9853 - val_loss: 0.5557 - val_accuracy: 0.8799\nEpoch 126/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 0.9865 - val_loss: 0.5632 - val_accuracy: 0.8873\nEpoch 127/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9859 - val_loss: 0.5358 - val_accuracy: 0.8922\nEpoch 128/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 0.9896 - val_loss: 0.5491 - val_accuracy: 0.8922\nEpoch 129/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9565 - val_loss: 0.5657 - val_accuracy: 0.8897\nEpoch 130/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0483 - accuracy: 0.9828 - val_loss: 0.5262 - val_accuracy: 0.8799\nEpoch 131/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.5816 - val_accuracy: 0.8848\nEpoch 132/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 0.5251 - val_accuracy: 0.8848\nEpoch 133/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9908 - val_loss: 0.5262 - val_accuracy: 0.8873\nEpoch 134/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9884 - val_loss: 0.5264 - val_accuracy: 0.8946\nEpoch 135/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9908 - val_loss: 0.5205 - val_accuracy: 0.8922\nEpoch 136/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9828 - val_loss: 0.5537 - val_accuracy: 0.8946\nEpoch 137/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.5744 - val_accuracy: 0.8897\nEpoch 138/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9877 - val_loss: 0.5293 - val_accuracy: 0.8922\nEpoch 139/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 0.9926 - val_loss: 0.5584 - val_accuracy: 0.8897\nEpoch 140/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 0.6071 - val_accuracy: 0.8922\nEpoch 141/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9877 - val_loss: 0.5494 - val_accuracy: 0.8873\nEpoch 142/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9834 - val_loss: 0.5781 - val_accuracy: 0.8897\nEpoch 143/200\n51/51 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.9847 - val_loss: 0.5506 - val_accuracy: 0.9020\nEpoch 144/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9822 - val_loss: 0.6066 - val_accuracy: 0.8873\nEpoch 145/200\n51/51 [==============================] - 0s 4ms/step - loss: 0.0282 - accuracy: 0.9914 - val_loss: 0.5510 - val_accuracy: 0.8897\nEpoch 146/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9828 - val_loss: 0.5770 - val_accuracy: 0.8922\nEpoch 147/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9822 - val_loss: 0.7006 - val_accuracy: 0.8922\nEpoch 148/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9804 - val_loss: 0.5990 - val_accuracy: 0.9020\nEpoch 149/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9945 - val_loss: 0.5448 - val_accuracy: 0.8897\nEpoch 150/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.6112 - val_accuracy: 0.8897\nEpoch 151/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9926 - val_loss: 0.6341 - val_accuracy: 0.8922\nEpoch 152/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.6282 - val_accuracy: 0.8897\nEpoch 153/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.6366 - val_accuracy: 0.8897\nEpoch 154/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.6439 - val_accuracy: 0.8873\nEpoch 155/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.9884 - val_loss: 0.6331 - val_accuracy: 0.8897\nEpoch 156/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9890 - val_loss: 0.6458 - val_accuracy: 0.8799\nEpoch 157/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9834 - val_loss: 0.6168 - val_accuracy: 0.8922\nEpoch 158/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 0.9945 - val_loss: 0.6564 - val_accuracy: 0.8922\nEpoch 159/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9963 - val_loss: 0.6539 - val_accuracy: 0.8897\nEpoch 160/200\n51/51 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.6638 - val_accuracy: 0.8848\nEpoch 161/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9914 - val_loss: 0.7676 - val_accuracy: 0.8848\nEpoch 162/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9693 - val_loss: 0.6308 - val_accuracy: 0.8775\nEpoch 163/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9884 - val_loss: 0.6425 - val_accuracy: 0.8897\nEpoch 164/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9914 - val_loss: 0.6016 - val_accuracy: 0.8922\nEpoch 165/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.5898 - val_accuracy: 0.8946\nEpoch 166/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.6378 - val_accuracy: 0.8971\nEpoch 167/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.7689 - val_accuracy: 0.8873\nEpoch 168/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.6667 - val_accuracy: 0.8824\nEpoch 169/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.6861 - val_accuracy: 0.8897\nEpoch 170/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9951 - val_loss: 0.6646 - val_accuracy: 0.8897\nEpoch 171/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9963 - val_loss: 0.6923 - val_accuracy: 0.8873\nEpoch 172/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.6228 - val_accuracy: 0.8873\nEpoch 173/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9853 - val_loss: 0.7256 - val_accuracy: 0.8897\nEpoch 174/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9877 - val_loss: 0.7661 - val_accuracy: 0.8824\nEpoch 175/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9755 - val_loss: 0.7050 - val_accuracy: 0.8824\nEpoch 176/200\n51/51 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 0.9896 - val_loss: 0.7531 - val_accuracy: 0.8873\nEpoch 177/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9908 - val_loss: 0.7562 - val_accuracy: 0.8922\nEpoch 178/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.6845 - val_accuracy: 0.8995\nEpoch 179/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 0.9994 - val_loss: 0.6929 - val_accuracy: 0.8922\nEpoch 180/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9975 - val_loss: 0.7321 - val_accuracy: 0.8873\nEpoch 181/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 0.7476 - val_accuracy: 0.8922\nEpoch 182/200\n51/51 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9975 - val_loss: 0.6877 - val_accuracy: 0.8873\nEpoch 183/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9994 - val_loss: 0.6840 - val_accuracy: 0.8971\nEpoch 184/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9884 - val_loss: 0.7395 - val_accuracy: 0.8946\nEpoch 185/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.7192 - val_accuracy: 0.8897\nEpoch 186/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9975 - val_loss: 0.7443 - val_accuracy: 0.8897\nEpoch 187/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9914 - val_loss: 0.9540 - val_accuracy: 0.8799\nEpoch 188/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9871 - val_loss: 0.7390 - val_accuracy: 0.8873\nEpoch 189/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.8468 - val_accuracy: 0.8946\nEpoch 190/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.9908 - val_loss: 0.7440 - val_accuracy: 0.8873\nEpoch 191/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.7077 - val_accuracy: 0.8848\nEpoch 192/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.8069 - val_accuracy: 0.8922\nEpoch 193/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 0.9877 - val_loss: 0.7891 - val_accuracy: 0.8897\nEpoch 194/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9681 - val_loss: 0.7382 - val_accuracy: 0.8873\nEpoch 195/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0417 - accuracy: 0.9828 - val_loss: 0.7328 - val_accuracy: 0.8922\nEpoch 196/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9920 - val_loss: 0.7191 - val_accuracy: 0.8873\nEpoch 197/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9982 - val_loss: 0.6912 - val_accuracy: 0.8873\nEpoch 198/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0111 - accuracy: 0.9982 - val_loss: 0.8142 - val_accuracy: 0.8873\nEpoch 199/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.8202 - val_accuracy: 0.8897\nEpoch 200/200\n51/51 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 0.7946 - val_accuracy: 0.8873\n13/13 [==============================] - 0s 1ms/step - loss: 0.7946 - accuracy: 0.8873\nAccuracy: 0.8872548937797546\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## GRU Model to predict the label","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GRU\n\n# Step 1: Load the CSV files\nsmiles_df = pd.read_csv('/kaggle/input/bbbp-dataset-ai-project/BBBP (1).csv')\ndescriptor_df = pd.read_csv('/kaggle/input/bbbp-dataset-ai-project/BBBP_descriptors_df.csv')\n\n# Step 2: Combine the data\ncombined_df = pd.concat([smiles_df, descriptor_df], axis=1)\n\n# Step 3: Preprocess the data\nfeatures = combined_df.drop(['label'], axis=1)\n\n# Remove non-numeric or string columns\nnumeric_cols = features.select_dtypes(include=['float64', 'int64']).columns\nfeatures = features[numeric_cols]\n\nlabels = combined_df['label']\n\n# Step 4: Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n\n# Step 5: Normalize the features\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Step 6: Build the GRU model\nmodel = Sequential()\nmodel.add(GRU(64, activation='relu', input_shape=(X_train_scaled.shape[1], 1)))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Step 7: Compile and train the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhistory = model.fit(X_train_scaled[:, :, np.newaxis], y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled[:, :, np.newaxis], y_test))\n\n# Step 8: Evaluate the model\nloss, accuracy = model.evaluate(X_test_scaled[:, :, np.newaxis], y_test)\nprint(f'Loss: {loss}, Accuracy: {accuracy}')\n\n# Step 9: Plot the training history\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T04:18:32.629854Z","iopub.execute_input":"2023-05-13T04:18:32.630119Z","iopub.status.idle":"2023-05-13T04:20:44.651789Z","shell.execute_reply.started":"2023-05-13T04:18:32.630095Z","shell.execute_reply":"2023-05-13T04:20:44.651098Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/10\n51/51 [==============================] - 14s 249ms/step - loss: 0.6080 - accuracy: 0.7548 - val_loss: 0.5595 - val_accuracy: 0.7574\nEpoch 2/10\n51/51 [==============================] - 13s 250ms/step - loss: 0.5503 - accuracy: 0.7670 - val_loss: 0.5622 - val_accuracy: 0.7574\nEpoch 3/10\n51/51 [==============================] - 13s 258ms/step - loss: 0.5439 - accuracy: 0.7670 - val_loss: 0.5512 - val_accuracy: 0.7574\nEpoch 4/10\n51/51 [==============================] - 12s 244ms/step - loss: 0.5348 - accuracy: 0.7670 - val_loss: 0.5468 - val_accuracy: 0.7574\nEpoch 5/10\n51/51 [==============================] - 13s 250ms/step - loss: 0.5188 - accuracy: 0.7689 - val_loss: 0.5375 - val_accuracy: 0.7598\nEpoch 6/10\n51/51 [==============================] - 14s 283ms/step - loss: 0.5113 - accuracy: 0.7799 - val_loss: 0.5335 - val_accuracy: 0.7623\nEpoch 7/10\n51/51 [==============================] - 13s 248ms/step - loss: 1.4374 - accuracy: 0.7670 - val_loss: 0.5844 - val_accuracy: 0.7672\nEpoch 8/10\n51/51 [==============================] - 12s 245ms/step - loss: 0.5284 - accuracy: 0.7713 - val_loss: 0.5373 - val_accuracy: 0.7574\nEpoch 9/10\n51/51 [==============================] - 13s 246ms/step - loss: 0.5082 - accuracy: 0.7750 - val_loss: 0.5334 - val_accuracy: 0.7647\nEpoch 10/10\n51/51 [==============================] - 12s 240ms/step - loss: 0.4968 - accuracy: 0.7842 - val_loss: 0.5339 - val_accuracy: 0.7721\n13/13 [==============================] - 1s 61ms/step - loss: 0.5339 - accuracy: 0.7721\nLoss: 0.5339183807373047, Accuracy: 0.7720588445663452\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"## GAN","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import accuracy_score\n\n\n# Step 1: Load the CSV files\nsmiles_df = pd.read_csv('/kaggle/input/bbbp-dataset-ai-project/BBBP (1).csv')\ndescriptor_df = pd.read_csv('/kaggle/input/bbbp-dataset-ai-project/BBBP_descriptors_df.csv')\n\n# Step 2: Combine the data\ncombined_df = pd.concat([smiles_df, descriptor_df], axis=1)\n\n# Step 3: Preprocess the data\nfeatures = combined_df.drop(['label'], axis=1)\n\n# Remove non-numeric or string columns\nnumeric_cols = features.select_dtypes(include=['float64', 'int64']).columns\nfeatures = features[numeric_cols]\n\nlabels = combined_df['label']\n\n# Step 4: Normalize the features\nscaler = MinMaxScaler()\nnormalized_features = scaler.fit_transform(features)\n\n# Step 5: Define the generator model\ngenerator = Sequential()\ngenerator.add(Dense(64, activation='relu', input_shape=(normalized_features.shape[1],)))\ngenerator.add(Dense(32, activation='relu'))\ngenerator.add(Dense(normalized_features.shape[1], activation='sigmoid'))\n\n# Step 6: Define the discriminator model\ndiscriminator = Sequential()\ndiscriminator.add(Dense(32, activation=LeakyReLU(alpha=0.2), input_shape=(normalized_features.shape[1],)))\ndiscriminator.add(Dense(16, activation=LeakyReLU(alpha=0.2)))\ndiscriminator.add(Dense(1, activation='sigmoid'))\n\n# Step 7: Combine the generator and discriminator into a GAN\ngan = Sequential()\ngan.add(generator)\ngan.add(discriminator)\n\n# Step 8: Compile the discriminator\ndiscriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n\n# Step 9: Compile the GAN\ndiscriminator.trainable = False\ngan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n\n# Step 10: Training loop\nbatch_size = 32\nepochs = 200\n\nfor epoch in range(epochs):\n    for batch in range(len(normalized_features) // batch_size):\n        # Step 10.1: Train the discriminator\n        batch_features = normalized_features[batch * batch_size: (batch + 1) * batch_size]\n        noise = np.random.normal(0, 1, size=(batch_size, normalized_features.shape[1]))\n        generated_features = generator.predict(noise)\n        real_labels = np.ones((batch_size, 1))\n        fake_labels = np.zeros((batch_size, 1))\n        \n        d_loss_real = discriminator.train_on_batch(batch_features, real_labels)\n        d_loss_fake = discriminator.train_on_batch(generated_features, fake_labels)\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n        \n        # Step 10.2: Train the generator\n        noise = np.random.normal(0, 1, size=(batch_size, normalized_features.shape[1]))\n        g_loss = gan.train_on_batch(noise, real_labels)\n        \n    # Step 10.3: Print the losses\n    print(f\"Epoch {epoch+1}/{epochs}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}\")\n    \n# Step 11: Generate synthetic samples\nnum_samples = 1000\nnoise = np.random.normal(0, 1, size=(num_samples, normalized_features.shape[1]))\ngenerated_samples = generator.predict(noise)\ngenerated_samples = scaler.inverse_transform(generated_samples)\n\n# Step 12: Visualize the synthetic samples\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x=generated_samples[:, 0], y=generated_samples[:, 1])\nplt.title(\"Generated Samples\")\nplt.xlabel(\"Feature 1\")\nplt.ylabel(\"Feature 2\")\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T04:20:44.652770Z","iopub.execute_input":"2023-05-13T04:20:44.653244Z"},"trusted":true},"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 72ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\nEpoch 1/200, Discriminator Loss: 0.12213939428329468, Generator Loss: 3.326629638671875\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\nEpoch 2/200, Discriminator Loss: 0.40298473834991455, Generator Loss: 2.902186870574951\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\nEpoch 3/200, Discriminator Loss: 0.28989575803279877, Generator Loss: 2.674039363861084\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\nEpoch 4/200, Discriminator Loss: 0.5508562326431274, Generator Loss: 1.9350999593734741\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\nEpoch 5/200, Discriminator Loss: 0.6470251679420471, Generator Loss: 1.9463516473770142\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\nEpoch 6/200, Discriminator Loss: 0.5965864658355713, Generator Loss: 1.1356755495071411\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 15ms/step\nEpoch 7/200, Discriminator Loss: 0.7228600978851318, Generator Loss: 1.1777430772781372\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\nEpoch 8/200, Discriminator Loss: 0.7334514558315277, Generator Loss: 0.9399381279945374\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\nEpoch 9/200, Discriminator Loss: 0.7143232524394989, Generator Loss: 0.9515834450721741\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 15ms/step\nEpoch 10/200, Discriminator Loss: 0.6452635228633881, Generator Loss: 0.8791784048080444\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\nEpoch 11/200, Discriminator Loss: 0.6857250928878784, Generator Loss: 0.9627228379249573\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\nEpoch 12/200, Discriminator Loss: 0.6625590622425079, Generator Loss: 0.7989935278892517\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 17ms/step\nEpoch 13/200, Discriminator Loss: 0.6892780363559723, Generator Loss: 0.8210318088531494\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\nEpoch 14/200, Discriminator Loss: 0.6989211440086365, Generator Loss: 0.9121617078781128\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\nEpoch 15/200, Discriminator Loss: 0.6576884090900421, Generator Loss: 0.8049746155738831\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\nEpoch 16/200, Discriminator Loss: 0.6154640913009644, Generator Loss: 0.9519699811935425\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 14ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\nEpoch 17/200, Discriminator Loss: 0.6925682723522186, Generator Loss: 0.9176641702651978\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\nEpoch 18/200, Discriminator Loss: 0.5761509239673615, Generator Loss: 1.0374904870986938\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 15ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 33ms/step\n1/1 [==============================] - 0s 21ms/step\nEpoch 19/200, Discriminator Loss: 0.6829359829425812, Generator Loss: 0.9799396395683289\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 28ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 19ms/step\nEpoch 20/200, Discriminator Loss: 0.5425167083740234, Generator Loss: 1.2174468040466309\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 16ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 20ms/step\n1/1 [==============================] - 0s 19ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 18ms/step\n1/1 [==============================] - 0s 17ms/step\n1/1 [==============================] - ETA: 0s","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import accuracy_score\n\n\n# Step 1: Load the CSV files\nsmiles_df = pd.read_csv('/kaggle/input/bbbp-dataset-ai-project/BBBP (1).csv')\ndescriptor_df = pd.read_csv('/kaggle/input/bbbp-dataset-ai-project/BBBP_descriptors_df.csv')\n\n# Step 2: Combine the data\ncombined_df = pd.concat([smiles_df, descriptor_df], axis=1)\n\n# Step 3: Preprocess the data\nfeatures = combined_df.drop(['label'], axis=1)\n\n# Remove non-numeric or string columns\nnumeric_cols = features.select_dtypes(include=['float64', 'int64']).columns\nfeatures = features[numeric_cols]\n\nlabels = combined_df['label']\n\n# Step 4: Normalize the features\nscaler = MinMaxScaler()\nnormalized_features = scaler.fit_transform(features)\n\n# Step 5: Define the generator model\ngenerator = Sequential()\ngenerator.add(Dense(64, activation='relu', input_shape=(normalized_features.shape[1],)))\ngenerator.add(Dense(32, activation='relu'))\ngenerator.add(Dense(normalized_features.shape[1], activation='sigmoid'))\n\n# Step 6: Define the discriminator model\ndiscriminator = Sequential()\ndiscriminator.add(Dense(32, activation=LeakyReLU(alpha=0.2), input_shape=(normalized_features.shape[1],)))\ndiscriminator.add(Dense(16, activation=LeakyReLU(alpha=0.2)))\ndiscriminator.add(Dense(1, activation='sigmoid'))\n\n# Step 7: Combine the generator and discriminator into a GAN\ngan = Sequential()\ngan.add(generator)\ngan.add(discriminator)\n\n# Step 8: Compile the discriminator\ndiscriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n\n# Step 9: Compile the GAN\ndiscriminator.trainable = False\ngan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n\n# Step 10: Training loop\nbatch_size = 32\nepochs = 200\n\nfor epoch in range(epochs):\n    for batch in range(len(normalized_features) // batch_size):\n        # Step 10.1: Train the discriminator\n        batch_features = normalized_features[batch * batch_size: (batch + 1) * batch_size]\n        noise = np.random.normal(0, 1, size=(batch_size, normalized_features.shape[1]))\n        generated_features = generator.predict(noise)\n        real_labels = np.ones((batch_size, 1))\n        fake_labels = np.zeros((batch_size, 1))\n        \n        d_loss_real = discriminator.train_on_batch(batch_features, real_labels)\n        d_loss_fake = discriminator.train_on_batch(generated_features, fake_labels)\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n        \n        # Step 10.2: Train the generator\n        noise = np.random.normal(0, 1, size=(batch_size, normalized_features.shape[1]))\n        g_loss = gan.train_on_batch(noise, real_labels)\n        \n    # Step 10.3: Print the losses\n    print(f\"Epoch {epoch+1}/{epochs}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}\")\n\n\n# Step 11: Generate synthetic samples\nnum_samples = 1000\nnoise = np.random.normal(0, 1, size=(num_samples, normalized_features.shape[1]))\ngenerated_samples = generator.predict(noise)\ngenerated_samples = scaler.inverse_transform(generated_samples)\n\n# Step 12: Create a separate classifier model\nclassifier = Sequential()\nclassifier.add(Dense(64, activation='relu', input_shape=(normalized_features.shape[1],)))\nclassifier.add(Dense(32, activation='relu'))\nclassifier.add(Dense(1, activation='sigmoid'))\n\n# Step 13: Compile and train the classifier on the original data\nX_train, X_test, y_train, y_test = train_test_split(normalized_features, labels, test_size=0.2, random_state=42)\nclassifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nclassifier.fit(X_train, y_train, epochs=10, batch_size=32)\n\n# Step 14: Evaluate the classifier on the generated samples\ngenerated_samples_normalized = scaler.transform(generated_samples)\ngenerated_samples_predictions = classifier.predict(generated_samples_normalized)\ngenerated_samples_predictions = np.round(generated_samples_predictions).flatten()\naccuracy = accuracy_score(np.ones(num_samples), generated_samples_predictions)\n\nprint(f\"Accuracy on Generated Samples: {accuracy}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Scaling and Principal component analysis (PCA) ","metadata":{"_uuid":"157cd38347003f810b36860da9785cbbac338db1"}},{"cell_type":"code","source":"bbbp_scaler1 = StandardScaler()\nbbbp_scaler1.fit(bbbp_descriptors_df.values)\nbbbp_descriptors_df = pd.DataFrame(bbbp_scaler1.transform(bbbp_descriptors_df.values),\n                                   columns=bbbp_descriptors_df.columns)","metadata":{"_uuid":"847505550ef7051fb8a3a8a2ed73e7be5149372b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The code snippet demonstrates the process of standardizing a dataset using the StandardScaler function from the scikit-learn library in Python. Standardization is a common preprocessing step in machine learning that aims to transform the data in a way that the features have zero mean and unit variance.\n\nIn the code, the StandardScaler object bbbp_scaler1 is created. It is then fitted to the values of the bbbp_descriptors_df DataFrame using the fit() method. This step calculates the mean and standard deviation of each feature in the dataset.\n\nNext, the transform() method is used to transform the original dataset (bbbp_descriptors_df.values) using the fitted scaler. This applies the standardization transformation to each feature in the DataFrame.\n\nThe resulting standardized dataset is assigned back to bbbp_descriptors_df, overwriting the original values. The DataFrame is now scaled, where each feature has a mean of 0 and a standard deviation of 1.\n\nStandardization is often performed to bring different features onto a similar scale, which can be beneficial for various machine learning algorithms, such as neural networks or support vector machines, that assume the features are normally distributed or have similar scales.","metadata":{}},{"cell_type":"code","source":"nca = NCA1\ncn = ['col'+str(x) for x in range(nca)]","metadata":{"_uuid":"559be8883fed83ca7441c4f0ee6140772e4a8149","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bbbp_transformer1 = KernelPCA(n_components=nca, kernel='rbf', n_jobs=-1)\nbbbp_transformer1.fit(bbbp_descriptors_df.values)\nbbbp_descriptors_df = pd.DataFrame(bbbp_transformer1.transform(bbbp_descriptors_df.values),\n                                   columns=cn)\nprint(bbbp_descriptors_df.shape)\nbbbp_descriptors_df.head()","metadata":{"_uuid":"91591e8dde4e8f8b44a8522973f071b1f23e4025","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(bbbp_descriptors_df.values, bbbp_df['label'].values.flatten(), \n                                                    test_size=TEST_RATIO, \n                                                    random_state=42,stratify=bbbp_df['label'].values.flatten())","metadata":{"_uuid":"d47f93361712ec31b371ac69c4e4e682c89bc899","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, \n                                                      test_size=VAL_RATIO, \n                                                      random_state=42,stratify=y_train)","metadata":{"_uuid":"f048f0c3b427b813fcf7687ae9c257d8409630b6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Find_Optimal_Cutoff(target, predicted):\n    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n    Parameters\n    ----------\n    target : Matrix with dependent or target data, where rows are observations\n\n    predicted : Matrix with predicted data, where rows are observations\n\n    Returns\n    -------     \n    list type, with optimal cutoff value\n\n    \"\"\"\n    fpr, tpr, threshold = roc_curve(target, predicted)\n    i = np.arange(len(tpr)) \n    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n\n    return list(roc_t['threshold']) ","metadata":{"_uuid":"942a8923cbade0e5b41d9042a0e6dbe0ec62e8a1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**The provided function, Find_Optimal_Cutoff, is used to determine the optimal probability cutoff point for a classification model based on the event rate.The purpose of this function is to determine the threshold (cutoff) probability that yields the optimal balance between true positive rate and false positive rate, as measured by the ROC curve.:**","metadata":{}},{"cell_type":"code","source":"def Find_Optimal_threshold(target, predicted):\n    target = target.reshape(-1,1)\n    predicted = predicted.reshape(-1,1)\n    \n    rng = np.arange(0.0, 0.99, 0.001)\n    f1s = np.zeros((rng.shape[0],predicted.shape[1]))\n    for i in range(0,predicted.shape[1]):\n        for j,t in enumerate(rng):\n            p = np.array((predicted[:,i])>t, dtype=np.int8)\n            scoref1 = f1_score(target[:,i], p, average='binary')\n            f1s[j,i] = scoref1\n            \n    threshold = np.empty(predicted.shape[1])\n    for i in range(predicted.shape[1]):\n        threshold[i] = rng[int(np.where(f1s[:,i] == np.max(f1s[:,i]))[0][0])]\n        \n    return threshold","metadata":{"_uuid":"251ca0682366804137e5e3c1ef0784a8c2505439","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**The provided function, Find_Optimal_threshold, is used to find the optimal threshold for a binary classification model based on the F1 score This function calculates the threshold that maximizes the F1 score for each column of the predicted data, providing a threshold selection strategy based on F1 score optimization.**","metadata":{}},{"cell_type":"markdown","source":"## Sklearn SVC Model","metadata":{"_uuid":"1a53a0f3da5434b8d67e0eaa170ba988ff40499b"}},{"cell_type":"markdown","source":"**The Sklearn SVC model refers to the Support Vector Classifier model provided by the scikit-learn library in Python. SVC is a supervised machine learning algorithm used for classification tasks.**\n\n**SVC is based on the concept of Support Vector Machines (SVM), which is a powerful algorithm for both classification and regression. In the case of classification, SVC aims to find an optimal hyperplane that separates the different classes in the feature space.**","metadata":{}},{"cell_type":"code","source":"parameters = {'kernel':['sigmoid', 'rbf'], 'C':[1,0.5], 'gamma':[1/nca,1/np.sqrt(nca)],'probability':[True]}\nbbbp_svc = GridSearchCV(SVC(random_state=23,class_weight='balanced'), parameters, cv=5, scoring='roc_auc',n_jobs=-1)","metadata":{"_uuid":"ebce39316cb4f24408cce65f832beee63e5acc33","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = bbbp_svc.fit(X_train, y_train)","metadata":{"_uuid":"fc276f599af57a895bed9310079ebf9390691fd4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(result.best_estimator_)","metadata":{"_uuid":"ef4ac87da30730b47b32ddfdc132d4a91a5d15ca","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The best_estimator_ attribute in scikit-learn represents the best estimator or model found during the hyperparameter tuning process using methods like GridSearchCV or RandomizedSearchCV. It gives you access to the trained estimator that achieved the best performance based on the specified scoring metric.","metadata":{}},{"cell_type":"code","source":"print(result.best_score_)","metadata":{"_uuid":"87579e1c257816966ad659f1a4a996ca39469cb3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = bbbp_svc.predict_proba(X_valid)","metadata":{"_uuid":"8fc2574652c60ab2a512cd8500f1469d432ef94d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Probability calibration:**\n\nSome models can give poor estimates of the class probabilities and some even do not support probability prediction. The *CalibratedClassifierCV*  calibrates the probabilities of a given model, or to add support for probability prediction.","metadata":{"_uuid":"fcddf010b8708dbdc14373aca8096c95d1c42145"}},{"cell_type":"code","source":"bbbp_svc_calib = CalibratedClassifierCV(bbbp_svc, cv='prefit')\nbbbp_svc_calib.fit(X_valid, y_valid)","metadata":{"_uuid":"00d9b398cfc716b7ccdd5f65bb0eece77b452c62","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = bbbp_svc_calib.predict_proba(X_valid)\npred = pred[:,1]\npred_svc_t = np.copy(pred)","metadata":{"_uuid":"016b157e0eb49ac36e2372732a92e8941bfb11cc","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"threshold = Find_Optimal_threshold(y_valid, pred)\nprint(threshold)","metadata":{"_uuid":"0792d4600043ae16dabdbdb891b41f7ec93e898b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = bbbp_svc_calib.predict(X_test)\nf1_score(y_test,pred)","metadata":{"_uuid":"55a73929d04744f6ec2073f101a6e245ffc63b71","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = bbbp_svc_calib.predict_proba(X_test)\nroc_auc_score(y_test,pred[:,1])","metadata":{"_uuid":"5c175e43bfd8f6a45127e5a9fbe3e8c91b5ef2d7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = pred[:,1]\npred_svc = np.copy(pred)\npred[pred<=threshold] = 0\npred[pred>threshold] = 1\nsvc_score = f1_score(y_test,pred)\nprint(svc_score)","metadata":{"_uuid":"54faab5ebe30cc95b58307461570ca112d3703af","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y = np.array(bbbp_descriptors_df.loc[23].values).reshape(1, -1)\nresult = bbbp_svc.predict(y)\nprob = bbbp_svc.predict_proba(y)\nprint(result)\nprint(prob)\nprint(int(prob[:,1]>threshold))","metadata":{"_uuid":"849a3a4344604c537dccdac0aaa476f8da2a5355","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Keras Neural Network Model","metadata":{"_uuid":"061496363ecdc73b4e8e61e7df17d693eb8b2335"}},{"cell_type":"code","source":"bbbp_model = Sequential()\nbbbp_model.add(Dense(128, input_dim=bbbp_descriptors_df.shape[1], \n                     kernel_initializer='he_uniform'))\nbbbp_model.add(BatchNormalization())\nbbbp_model.add(Activation('tanh'))\nbbbp_model.add(Dropout(rate=DROPRATE))\nbbbp_model.add(Dense(64,kernel_initializer='he_uniform'))\nbbbp_model.add(BatchNormalization())\nbbbp_model.add(Activation('tanh'))\nbbbp_model.add(Dropout(rate=DROPRATE))\nbbbp_model.add(Dense(32,kernel_initializer='he_uniform'))\nbbbp_model.add(BatchNormalization())\nbbbp_model.add(Activation('tanh'))\nbbbp_model.add(Dropout(rate=DROPRATE))\nbbbp_model.add(Dense(1,kernel_initializer='he_uniform',activation='sigmoid'))","metadata":{"_uuid":"7113e32add705b2e9f04c4376417baf588d98fad","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bbbp_model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])","metadata":{"_uuid":"083f44c640f5d65d0c04125c748d1cd598bc13d5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('bbbp_model.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')","metadata":{"_uuid":"31218b2bc94430d042033e8d260fe5ffad27f2d4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_classes = np.unique(bbbp_df['label'].values.flatten())\nclasses = bbbp_df['label'].values.flatten()\nclass_weights = class_weight.compute_class_weight(class_weight = 'balanced',\n                                                  classes = np.unique(bbbp_df['label'].values.flatten()),\n                                                  y = bbbp_df['label'].values.flatten())\nclass_weights = {unique_classes[0]:class_weights[0],unique_classes[1]:class_weights[1]}","metadata":{"_uuid":"ad06bd823a5c8b79da5579a51bd040afa01e37e3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hist = bbbp_model.fit(X_train, y_train, \n                      validation_data=(X_valid,y_valid),epochs=EP, batch_size=BATCH_SIZE, \n                      class_weight=class_weights ,callbacks=[checkpoint])","metadata":{"_uuid":"23b5a0ff88474ca73e3c2e4b08cf252bec50b0c6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.ylim(0., 1.0)\nplt.plot(hist.epoch, hist.history[\"loss\"], label=\"Train loss\")\nplt.plot(hist.epoch, hist.history[\"val_loss\"], label=\"Valid loss\")","metadata":{"_uuid":"f4ea5b8eb164011d1c69979361ee225496776df2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bbbp_model.load_weights('bbbp_model.h5')","metadata":{"_uuid":"5f7724a332be6a9f671c75c55a8f67662de22529","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = bbbp_model.predict(X_valid)\npred_nn_t = np.copy(pred)","metadata":{"_uuid":"e92a97b1fafb1bcd88bb1fc0644f97bcfd73aea2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"threshold = Find_Optimal_threshold(y_valid, pred)\nprint(threshold)","metadata":{"_uuid":"5b76005aebc297af507ca7eced58ef02d2fffefc","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## AUC SCORE","metadata":{}},{"cell_type":"code","source":"pred = bbbp_model.predict(X_test)\npred_nn = np.copy(pred)\nroc_auc_score(y_test,pred)","metadata":{"_uuid":"a13372a9a8d6cc6d5d511644a94d8b24cd9a6373","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## F1 SCORE ","metadata":{}},{"cell_type":"code","source":"pred[pred<=threshold] = 0\npred[pred>threshold] = 1\nnn_score = f1_score(y_test,pred)\nprint(nn_score)","metadata":{"_uuid":"05307f256bbad438a57d4dea3bad9c459c5d871f","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Accuracy","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Convert the predicted probabilities to binary predictions\npred_binary = (pred > threshold).astype(int)\n\n# Compute accuracy\naccuracy = accuracy_score(y_test, pred_binary)\n\n# Convert accuracy to percentage\naccuracy_percent = accuracy * 100\n\nprint(f'Accuracy: {accuracy_percent:.2f}%')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Gradient Boosting of Keras Model with SVC","metadata":{"_uuid":"07a5dcffc37d749e7b11d3811b7dfcaee6c31a85"}},{"cell_type":"code","source":"inp = bbbp_model.input\nout = bbbp_model.layers[-2].output\nbbbp_model_gb = Model(inp, out)","metadata":{"_uuid":"6dcd13e47350f3459a3bda94bd7254a47c925029","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = bbbp_model_gb.predict(X_train)\nX_valid = bbbp_model_gb.predict(X_valid)\nX_test = bbbp_model_gb.predict(X_test)","metadata":{"_uuid":"835deec8e5b71888165f0e55f304267b3dd5953e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = np.concatenate((X_train,X_test,X_valid),axis=0)","metadata":{"_uuid":"2622e6161c8f4b7636da3a83709bf214d20ed60a","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bbbp_scaler2 = StandardScaler()\nbbbp_scaler2.fit(data)\nX_train = bbbp_scaler2.transform(X_train)\nX_valid = bbbp_scaler2.transform(X_valid)\nX_test = bbbp_scaler2.transform(X_test)","metadata":{"_uuid":"6f3a07d1cd36413ef3daf0bf233340787ac2bf4d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = np.concatenate((X_train,X_test,X_valid),axis=0)","metadata":{"_uuid":"ee7ab0ac794f22b9d8eac8f5cb916ba233a25a7e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nca = NCA2","metadata":{"_uuid":"1ed210631129732b7809cca2488b4dd4005c100a","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bbbp_transformer2 = KernelPCA(n_components=nca, kernel='rbf', n_jobs=-1)\nbbbp_transformer2.fit(data)\nX_train = bbbp_transformer2.transform(X_train)\nX_valid = bbbp_transformer2.transform(X_valid)\nX_test = bbbp_transformer2.transform(X_test)","metadata":{"_uuid":"1b716cac43c839dc894db3506d817b76b2dfeb46","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nca = X_train.shape[1]\nparameters = {'kernel':['sigmoid', 'rbf'], 'C':[1,0.5], 'gamma':[1/nca,1/np.sqrt(nca)],'probability':[True]}\nbbbp_svc_gb = GridSearchCV(SVC(random_state=23,class_weight='balanced'), parameters, cv=5, scoring='roc_auc',n_jobs=-1)","metadata":{"_uuid":"b8b1384488506c67177966d02d64cd84f9e4ed50","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = bbbp_svc_gb.fit(X_train, y_train)","metadata":{"_uuid":"ee40cbad1cccd9f0f356626e74489193ff70a2b1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(result.best_estimator_)","metadata":{"_uuid":"2f4dc8f80444d1a3deef0e2fb11818321eb43666","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Best Score**","metadata":{}},{"cell_type":"code","source":"print(result.best_score_)","metadata":{"_uuid":"a9c82fc5293fd10a5f084e7bc2a8ee549050ce03","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = bbbp_svc_gb.predict_proba(X_valid)","metadata":{"_uuid":"7fad4c9c08b81ff8b4472349664aa0d3446c79e8","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bbbp_svc_gb_calib = CalibratedClassifierCV(bbbp_svc_gb, cv='prefit')\nbbbp_svc_gb_calib.fit(X_valid, y_valid)","metadata":{"_uuid":"7ad4fecde33c8fba0142370f6d6c578c0a7ab093","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = bbbp_svc_gb_calib.predict_proba(X_valid)\npred = pred[:,1]\npred_svc_gb_t = np.copy(pred)","metadata":{"_uuid":"4b00925f1699e21e2ffd710689885050a0404fb6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"threshold = Find_Optimal_threshold(y_valid, pred)\nprint(threshold)","metadata":{"_uuid":"933cf4b4cb96171082713a852e0c5510af51f2e5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = bbbp_svc_gb_calib.predict(X_test)\nf1_score(y_test,pred)","metadata":{"_uuid":"50c0ef3adfd3cfd694c1879b52d65167c4c6963c","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## AUC SCORE","metadata":{}},{"cell_type":"code","source":"pred = bbbp_svc_gb_calib.predict_proba(X_test)\nroc_auc_score(y_test,pred[:,1])","metadata":{"_uuid":"e6bde9d66739ad860b2286f9d0652c482b086382","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## F1 SCORE","metadata":{}},{"cell_type":"code","source":"pred = pred[:,1]\npred_svc_gb = np.copy(pred)\npred[pred<=threshold] = 0\npred[pred>threshold] = 1\nsvc_gb_score = f1_score(y_test,pred)\nprint(svc_gb_score)","metadata":{"_uuid":"2031f7c8e55c5c6dd8eb88b71a869af11d9bbe94","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Accuracy","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Convert the predicted probabilities to binary predictions\npred_binary = (pred > threshold).astype(int)\n\n# Compute accuracy\naccuracy = accuracy_score(y_test, pred_binary)\n\n# Convert accuracy to percentage\naccuracy_percent = accuracy * 100\n\nprint(f'Accuracy: {accuracy_percent:.2f}%')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Gradient Boosting of Keras Model with XGBoost","metadata":{"_uuid":"96fd5dd2b70a945a81d2dc73a31d36e8d32754e6"}},{"cell_type":"code","source":"parameters = {'learning_rate':[0.05,0.1,0.15],'n_estimators':[75,100,125], 'max_depth':[3,4,5],\n               'booster':['gbtree','dart'],'reg_alpha':[0.,0.1,0.05],'reg_lambda':[0.,0.1,0.5,1.]}\n\nbbbp_xgb_gb = GridSearchCV(XGBClassifier(random_state=32), parameters, cv=5, scoring='roc_auc',n_jobs=-1)","metadata":{"_uuid":"65c0488333a18a8dbd948e2707fc365c0bedbcea","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = bbbp_xgb_gb.fit(X_train, y_train)","metadata":{"_uuid":"1851754076a63d9e5694ffd5906c5daad272cadb","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(result.best_estimator_)","metadata":{"_uuid":"45215de7c6371f4f18645c12568589c9c13fc7ab","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(result.best_score_)","metadata":{"_uuid":"3f6e18a9aa3116af2a30a2e739dd4f4f5c90745b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = bbbp_xgb_gb.predict_proba(X_valid)","metadata":{"_uuid":"e3941346e7fb7b8f3c785eabee69e715e1d154b7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bbbp_xgb_gb_calib = CalibratedClassifierCV(bbbp_xgb_gb, cv='prefit')\nbbbp_xgb_gb_calib.fit(X_valid, y_valid)","metadata":{"_uuid":"8d16c67f83a7d9087d316838d61d519ecf162597","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = bbbp_xgb_gb.predict_proba(X_valid)\npred = pred[:,1]\npred_xgb_gb_t= np.copy(pred)","metadata":{"_uuid":"943e3d20aae5af8eefccc6a37b3c8e544c7a5543","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"threshold = Find_Optimal_threshold(y_valid, pred)\nprint(threshold)","metadata":{"_uuid":"f36f68e469090c29f390f5b0988e3b8a40045642","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = bbbp_xgb_gb_calib.predict(X_test)\nf1_score(y_test,pred)","metadata":{"_uuid":"0847851221d7ffe3a3e8af683f7edafaeccd1d81","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = bbbp_xgb_gb_calib.predict_proba(X_test)\nroc_auc_score(y_test,pred[:,1])","metadata":{"_uuid":"e8db961cad19a3e7d935b652051121613f65c2e0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = pred[:,1]\npred_xgb_gb = np.copy(pred)\npred[pred<=threshold] = 0\npred[pred>threshold] = 1\nxgb_gb_score = f1_score(y_test,pred)\nprint(xgb_gb_score)","metadata":{"_uuid":"3830e9abad368ff844df9de7412d2735bbe9e2b3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = (pred_svc_t+pred_nn_t.flatten()+pred_svc_gb_t+pred_xgb_gb_t)/4.","metadata":{"_uuid":"1d1b651af3d8a4e7f1569bde5dc899993d03d029","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"threshold = Find_Optimal_threshold(y_valid, pred)\nprint(threshold)","metadata":{"_uuid":"8b55fcc493061f5bdf7a7e8f64e6b8182c9da439","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred = (pred_svc+pred_nn.flatten()+pred_svc_gb+pred_xgb_gb)/4.\npred[pred<=threshold] = 0\npred[pred>threshold] = 1\nave_score = f1_score(y_test,pred)","metadata":{"_uuid":"1412c57c4cb7196b5c196cb7a31ff6627b808d56","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Saving models, transformer and scaler","metadata":{"_uuid":"f6383fe922bb87d2367ccb675c7c928d292d6cd5"}},{"cell_type":"code","source":"with open('bbbp_transformer1.pkl', 'wb') as fid:\n    pickle.dump(bbbp_transformer1, fid)\nwith open('bbbp_transformer2.pkl', 'wb') as fid:\n    pickle.dump(bbbp_transformer2, fid)\nwith open('bbbp_scaler1.pkl', 'wb') as fid:\n    pickle.dump(bbbp_scaler1, fid)\nwith open('bbbp_scaler2.pkl', 'wb') as fid:\n    pickle.dump(bbbp_scaler2, fid)\nwith open('bbbp_svc_calib.pkl', 'wb') as fid:\n    pickle.dump(bbbp_svc_calib, fid)\nwith open('bbbp_svc.pkl', 'wb') as fid:\n    pickle.dump(bbbp_svc, fid)\nwith open('bbbp_svc_gb_calib.pkl', 'wb') as fid:\n    pickle.dump(bbbp_svc_gb_calib, fid)\nwith open('bbbp_svc_gb.pkl', 'wb') as fid:\n    pickle.dump(bbbp_svc_gb, fid)\nwith open('bbbp_xgb_gb_calib.pkl', 'wb') as fid:\n    pickle.dump(bbbp_xgb_gb_calib, fid)\nwith open('bbbp_xgb_gb.pkl', 'wb') as fid:\n    pickle.dump(bbbp_xgb_gb, fid)","metadata":{"_uuid":"9597d9beb7f6e67a2a21ffc7ca61b9279414e14d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## For loading saved model\n\n```python\nwith open('bbbp_svc.pkl', 'rb') as fid:\n    bbbp_svc = pickle.load(fid)\n ```","metadata":{"_uuid":"6f583862055407aca34e59420385e7563e0b40d3"}},{"cell_type":"markdown","source":"## F1 Score Result","metadata":{"_uuid":"d36fc2cb183d483a852e14530ee18764d48c0039"}},{"cell_type":"markdown","source":"### sns.set(style=\"whitegrid\")\nax = sns.barplot(x=[svc_score,nn_score,svc_gb_score,xgb_gb_score,ave_score],\n                 y=['SVC','NN','SVC_GB','XGB_GB','ave'])\nax.set(xlim=(0.75, None))","metadata":{"_uuid":"e1450e16e14d1507ade8a5bffbbe5c8721d1eedc"}}]}